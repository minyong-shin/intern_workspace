{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import requests\n",
    "import re\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver import Chrome\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser = Chrome()\n",
    "delay = 3\n",
    "base_url = 'https://cafe.naver.com/thankmall'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.get(base_url)\n",
    "browser.implicitly_wait(delay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.find_element_by_css_selector('span.gnb_txt').click()\n",
    "browser.implicitly_wait(delay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 네이버 로그인 보안 강화로 코드로 접속 불가, 직접 쳐야한다.\n",
    "#### browser.find_element_by_name('id').send_keys(naver_id)\n",
    "#### browser.find_element_by_name('pw').send_keys(naver_pw)\n",
    "#### browser.find_element_by_css_selector('input.btn_global').send_keys(Keys.ENTER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cafe_menu = browser.find_element_by_css_selector('div#cafe-menu')\n",
    "browser.implicitly_wait(delay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "menu_list = cafe_menu.find_elements_by_tag_name('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "menu_source = pd.DataFrame({'name' : [], 'source' : []})\n",
    "name = []\n",
    "source = []\n",
    "\n",
    "for menu in menu_list :\n",
    "    menu_name = menu.text\n",
    "    if '전체글' in menu_name : # 원하는 검색어를 집어넣어야 한다.\n",
    "        insert_menu = pd.DataFrame({'name' : [menu_name], 'source' : [menu]})\n",
    "        menu_source = menu_source.append(insert_menu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "menu_source.index = range(len(menu_source))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>전체글보기</td>\n",
       "      <td>&lt;selenium.webdriver.remote.webelement.WebEleme...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    name                                             source\n",
       "0  전체글보기  <selenium.webdriver.remote.webelement.WebEleme..."
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "menu_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 원하는 카테고리 클릭을 위해서 인덱싱을 진행하는데, 앞에부분만 바꾸면된다.\n",
    "menu_source.iloc[0,1].send_keys(Keys.ENTER)\n",
    "                                            \n",
    "browser.implicitly_wait(delay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: DeprecationWarning: use driver.switch_to.frame instead\n",
      "  \n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-da08e08204f1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[1;32mtry\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m                 \u001b[0mbrowser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mswitch_to_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbrowser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cafe_main'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m                 \u001b[0mpage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbrowser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_css_selector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'div.prev-next'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mfind_element_by_name\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    495\u001b[0m         \"\"\"\n\u001b[1;32m--> 496\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNAME\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    497\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mfind_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    977\u001b[0m             \u001b[1;34m'using'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 978\u001b[1;33m             'value': value})['value']\n\u001b[0m\u001b[0;32m    979\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 321\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    322\u001b[0m             response['value'] = self._unwrap_value(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    241\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"name\",\"selector\":\"cafe_main\"}\n  (Session info: chrome=71.0.3578.98)\n  (Driver info: chromedriver=2.45.615291 (ec3682e3c9061c10f26ea9e5cdcf3c53f3f74387),platform=Windows NT 10.0.17134 x86_64)\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-da08e08204f1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     28\u001b[0m                 \u001b[0mpage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbrowser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_css_selector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'div.prev-next'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m                 \u001b[0mpage_num\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_elements_by_tag_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'a'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m                 \u001b[1;32mif\u001b[0m \u001b[1;34m'다음'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpage_num\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnum\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m                     \u001b[0mpage_num\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnum\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_keys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mENTER\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "post_list = pd.DataFrame({'name' : [],\n",
    "                         'user' : [],\n",
    "                         'time' : [],\n",
    "                         'link' : []})\n",
    "while True :\n",
    "    try :\n",
    "        browser.switch_to_frame(browser.find_element_by_name('cafe_main'))\n",
    "        page = browser.find_element_by_css_selector('div.prev-next')\n",
    "        page_num = page.find_elements_by_tag_name('a')\n",
    "    except :\n",
    "        page = browser.find_element_by_css_selector('div.prev-next')\n",
    "        page_num = page.find_elements_by_tag_name('a')        \n",
    "    \n",
    "    for num in range(len(page_num)) :           \n",
    "            try :  \n",
    "                browser.switch_to_frame(browser.find_element_by_name('cafe_main'))\n",
    "                page = browser.find_element_by_css_selector('div.prev-next')\n",
    "                page_num = page.find_elements_by_tag_name('a')\n",
    "                if '다음' in page_num[num].text :\n",
    "                    page_num[num].send_keys(Keys.ENTER)\n",
    "                    break\n",
    "                elif '이전' in page_num[num].text :\n",
    "                    pass\n",
    "                else :\n",
    "                    page_num[num].send_keys(Keys.ENTER)\n",
    "            except :\n",
    "                page = browser.find_element_by_css_selector('div.prev-next')\n",
    "                page_num = page.find_elements_by_tag_name('a')\n",
    "                if '다음' in page_num[num].text :\n",
    "                    page_num[num].send_keys(Keys.ENTER)\n",
    "                    break        \n",
    "                elif '이전' in page_num[num].text :\n",
    "                    pass\n",
    "                else :\n",
    "                    page_num[num].send_keys(Keys.ENTER)\n",
    "                \n",
    "            source = browser.page_source\n",
    "            html = BeautifulSoup(source, 'html.parser')\n",
    "            tbody = html.find_all('div', {'class' : 'article-board m-tcol-c'})\n",
    "            post_name = tbody[1].find_all('a', {'class' :'article'})\n",
    "            post_user = tbody[1].find_all('a', {'class' : 'm-tcol-c'})\n",
    "            post_time = tbody[1].find_all('td', {'class' : 'td_date'})\n",
    "\n",
    "            name = []\n",
    "            user = []\n",
    "            time = []\n",
    "            link = []\n",
    "\n",
    "            for n in post_name :\n",
    "                n = n.text.replace('\\n','')\n",
    "                name.append(re.sub(r' {2,}' , ' ', n))\n",
    "                \n",
    "            for u in post_user :\n",
    "                user.append(u.text)\n",
    "\n",
    "            for t in post_time :\n",
    "                time.append(re.sub('[^0-9\\.\\:]', '', t.text))\n",
    "                \n",
    "            for l in range(len(post_name)) :\n",
    "                post_link = base_url + post_name[l]['href']\n",
    "                link.append(post_link)\n",
    "\n",
    "            posting = pd.DataFrame({'name' : name,\n",
    "                                    'user' : user,\n",
    "                                    'time' : time,\n",
    "                                   'link' : link})\n",
    "\n",
    "            post_list = post_list.append(posting)\n",
    "\n",
    "    if len(page_num) < 11 :\n",
    "        break\n",
    "    \n",
    "post_list = post_list.drop_duplicates(subset='name', keep='last')\n",
    "post_list.index = range(len(post_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>user</th>\n",
       "      <th>time</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[ 퀄리티 최상급 ] [ 아동복 국산 브랜드 &gt;&gt; 땡처리 합니다 ]</td>\n",
       "      <td>멕가이버</td>\n",
       "      <td>15:41</td>\n",
       "      <td>https://cafe.naver.com/thankmall/ArticleRead.n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[완사입/파샬]퀄리티 좋은 봄 쟈가드 롱 가디건 2컬러 - 200여장 8000원</td>\n",
       "      <td>가비야IPKOREA</td>\n",
       "      <td>14:19</td>\n",
       "      <td>https://cafe.naver.com/thankmall/ArticleRead.n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[완사입] 언발롱셔츠 - 5장 5000원</td>\n",
       "      <td>가비야IPKOREA</td>\n",
       "      <td>2019.02.07.</td>\n",
       "      <td>https://cafe.naver.com/thankmall/ArticleRead.n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[완사입/파샬] 미시간 쭈리 원피스 2컬러 - 34장 4000원</td>\n",
       "      <td>가비야IPKOREA</td>\n",
       "      <td>2019.02.07.</td>\n",
       "      <td>https://cafe.naver.com/thankmall/ArticleRead.n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>행복한 설명절되세요~~~~~~^^</td>\n",
       "      <td>작은별</td>\n",
       "      <td>2019.02.03.</td>\n",
       "      <td>https://cafe.naver.com/thankmall/ArticleRead.n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>쿠첸생산 수출IH다이야몬드철정압력밥솥 10인용</td>\n",
       "      <td>새영</td>\n",
       "      <td>2019.02.03.</td>\n",
       "      <td>https://cafe.naver.com/thankmall/ArticleRead.n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>차렵이불.패드입니다</td>\n",
       "      <td>물고기사랑</td>\n",
       "      <td>2019.02.03.</td>\n",
       "      <td>https://cafe.naver.com/thankmall/ArticleRead.n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>새해 복 많이 받으세요~~~</td>\n",
       "      <td>phss0802</td>\n",
       "      <td>2019.02.02.</td>\n",
       "      <td>https://cafe.naver.com/thankmall/ArticleRead.n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>아동 봄 상하세트 110셋</td>\n",
       "      <td>마마미</td>\n",
       "      <td>2019.02.02.</td>\n",
       "      <td>https://cafe.naver.com/thankmall/ArticleRead.n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>여성 봄니트 대봉 3만원</td>\n",
       "      <td>지구정복</td>\n",
       "      <td>2019.02.02.</td>\n",
       "      <td>https://cafe.naver.com/thankmall/ArticleRead.n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>여성 티셔츠 1000원</td>\n",
       "      <td>지구정복</td>\n",
       "      <td>2019.02.02.</td>\n",
       "      <td>https://cafe.naver.com/thankmall/ArticleRead.n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>망원동~ 옷가게 하실분</td>\n",
       "      <td>gurione6708</td>\n",
       "      <td>2019.02.02.</td>\n",
       "      <td>https://cafe.naver.com/thankmall/ArticleRead.n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4가지싸게처분합니다 먼저가져가심 임자</td>\n",
       "      <td>새영</td>\n",
       "      <td>2019.02.02.</td>\n",
       "      <td>https://cafe.naver.com/thankmall/ArticleRead.n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>아동봄상하세트</td>\n",
       "      <td>마마미</td>\n",
       "      <td>2019.02.01.</td>\n",
       "      <td>https://cafe.naver.com/thankmall/ArticleRead.n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>쇼핑몰정리 의류재고처리 쇼핑몰폐업 동대문땡처리 땡처리매입 여성의류땡처리 대고의류 ...</td>\n",
       "      <td>더미더미</td>\n",
       "      <td>2019.02.01.</td>\n",
       "      <td>https://cafe.naver.com/thankmall/ArticleRead.n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>몽땅 6만원</td>\n",
       "      <td>물고기사랑</td>\n",
       "      <td>2019.02.01.</td>\n",
       "      <td>https://cafe.naver.com/thankmall/ArticleRead.n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>여성 oem 모직 반바지 장당 한가지 장당 1500원</td>\n",
       "      <td>마유리</td>\n",
       "      <td>2019.02.01.</td>\n",
       "      <td>https://cafe.naver.com/thankmall/ArticleRead.n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>핸드메이드 롱코트 난닝구제품</td>\n",
       "      <td>사재기대마왕</td>\n",
       "      <td>2019.02.01.</td>\n",
       "      <td>https://cafe.naver.com/thankmall/ArticleRead.n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>봄 쟈켓</td>\n",
       "      <td>예쁜옷사고시펑</td>\n",
       "      <td>2019.02.01.</td>\n",
       "      <td>https://cafe.naver.com/thankmall/ArticleRead.n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>아동 봄옷 300장 특가</td>\n",
       "      <td>마마미</td>\n",
       "      <td>2019.02.01.</td>\n",
       "      <td>https://cafe.naver.com/thankmall/ArticleRead.n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[완사입] 스트라이프 단가라 10장 -3000원</td>\n",
       "      <td>가비야IPKOREA</td>\n",
       "      <td>2019.02.01.</td>\n",
       "      <td>https://cafe.naver.com/thankmall/ArticleRead.n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>삠뽀요 아동 야상</td>\n",
       "      <td>머스 캣</td>\n",
       "      <td>2019.02.01.</td>\n",
       "      <td>https://cafe.naver.com/thankmall/ArticleRead.n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>선착순 무료 나눔 합니다~!</td>\n",
       "      <td>준배파파</td>\n",
       "      <td>2019.02.01.</td>\n",
       "      <td>https://cafe.naver.com/thankmall/ArticleRead.n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>아동상하세트</td>\n",
       "      <td>마마미</td>\n",
       "      <td>2019.02.01.</td>\n",
       "      <td>https://cafe.naver.com/thankmall/ArticleRead.n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[완사입] 낱장 원피스 10장 -6000원</td>\n",
       "      <td>가비야IPKOREA</td>\n",
       "      <td>2019.02.01.</td>\n",
       "      <td>https://cafe.naver.com/thankmall/ArticleRead.n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[완사입/파샬] 여성 반목 베이지 티셔츠 5컬러 -69장 1500원</td>\n",
       "      <td>가비야IPKOREA</td>\n",
       "      <td>2019.02.01.</td>\n",
       "      <td>https://cafe.naver.com/thankmall/ArticleRead.n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[완사입/파샬] 여자친구원피스 - 38장 3500원</td>\n",
       "      <td>가비야IPKOREA</td>\n",
       "      <td>2019.02.01.</td>\n",
       "      <td>https://cafe.naver.com/thankmall/ArticleRead.n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>복 많이 받으세요</td>\n",
       "      <td>빈티지 다온</td>\n",
       "      <td>2019.02.01.</td>\n",
       "      <td>https://cafe.naver.com/thankmall/ArticleRead.n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[완사입/파샬] 언발체크셔츠원피스 - 50장 3500원</td>\n",
       "      <td>가비야IPKOREA</td>\n",
       "      <td>2019.02.01.</td>\n",
       "      <td>https://cafe.naver.com/thankmall/ArticleRead.n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>아동팬티</td>\n",
       "      <td>물고기사랑</td>\n",
       "      <td>2019.02.01.</td>\n",
       "      <td>https://cafe.naver.com/thankmall/ArticleRead.n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9126</th>\n",
       "      <td>여성등산화 450족 잔여수량 땡처리합니다. -판매완료</td>\n",
       "      <td>토끼</td>\n",
       "      <td>2014.12.09.</td>\n",
       "      <td>https://cafe.naver.com/thankmall/ArticleRead.n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9127</th>\n",
       "      <td>브랜드 어그부츠 .... 밑창 확대해서보세요.. 이보다 더 짱짱할수 없는 어그 입...</td>\n",
       "      <td>토끼</td>\n",
       "      <td>2014.12.09.</td>\n",
       "      <td>https://cafe.naver.com/thankmall/ArticleRead.n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9128</th>\n",
       "      <td>요즘 인기있는 디자인 몇가지 첨부해 봅니다.. -판매완료</td>\n",
       "      <td>토끼</td>\n",
       "      <td>2014.12.05.</td>\n",
       "      <td>https://cafe.naver.com/thankmall/ArticleRead.n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9129</th>\n",
       "      <td>어그부츠.-픔절..</td>\n",
       "      <td>토끼</td>\n",
       "      <td>2014.12.02.</td>\n",
       "      <td>https://cafe.naver.com/thankmall/ArticleRead.n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9130</th>\n",
       "      <td>2014년 신상 여성화 땡처리 합니다... 디자인별 수량이 많치 않아요.. 구경먼...</td>\n",
       "      <td>토끼</td>\n",
       "      <td>2014.11.26.</td>\n",
       "      <td>https://cafe.naver.com/thankmall/ArticleRead.n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9131</th>\n",
       "      <td>어그부츠 1500족 들어왔습니다. -판매완료-</td>\n",
       "      <td>토끼</td>\n",
       "      <td>2014.11.24.</td>\n",
       "      <td>https://cafe.naver.com/thankmall/ArticleRead.n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9132</th>\n",
       "      <td>아동 패딩. 어그부츠 땡처리합니다. -판매완료-</td>\n",
       "      <td>토끼</td>\n",
       "      <td>2014.11.19.</td>\n",
       "      <td>https://cafe.naver.com/thankmall/ArticleRead.n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9133</th>\n",
       "      <td>국산 사슴어그부츠 &gt;&gt; 동대문 도매가 반가격 땡처리 합니다. -판매완료</td>\n",
       "      <td>토끼</td>\n",
       "      <td>2014.11.19.</td>\n",
       "      <td>https://cafe.naver.com/thankmall/ArticleRead.n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9134</th>\n",
       "      <td>엄마랑 아가랑 커플 사슴어그 입니다. -판매완료</td>\n",
       "      <td>토끼</td>\n",
       "      <td>2014.11.19.</td>\n",
       "      <td>https://cafe.naver.com/thankmall/ArticleRead.n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9135</th>\n",
       "      <td>아동부츠 잔여수량 200족 -판매완료</td>\n",
       "      <td>토끼</td>\n",
       "      <td>2014.11.19.</td>\n",
       "      <td>https://cafe.naver.com/thankmall/ArticleRead.n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9136</th>\n",
       "      <td>사슴 어그 요-판매완료</td>\n",
       "      <td>토끼</td>\n",
       "      <td>2014.11.19.</td>\n",
       "      <td>https://cafe.naver.com/thankmall/ArticleRead.n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9137</th>\n",
       "      <td>작은싸이즈 부츠 랜덤 3000원 입니다. 최소수량 50족 -수량 조절 가능 &lt;판매...</td>\n",
       "      <td>토끼</td>\n",
       "      <td>2014.11.17.</td>\n",
       "      <td>https://cafe.naver.com/thankmall/ArticleRead.n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9138</th>\n",
       "      <td>아동 부츠 2500족 완사 진행제품입니다. 가격조정해서 파샬구입도 가능합니다. -...</td>\n",
       "      <td>토끼</td>\n",
       "      <td>2014.11.17.</td>\n",
       "      <td>https://cafe.naver.com/thankmall/ArticleRead.n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9139</th>\n",
       "      <td>매년 없어서 못파는 안에 털들은 앵글부츠 입니다. -품절 임박</td>\n",
       "      <td>토끼</td>\n",
       "      <td>2014.11.17.</td>\n",
       "      <td>https://cafe.naver.com/thankmall/ArticleRead.n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9140</th>\n",
       "      <td>4차물량&gt;&gt;숏 어그부츠 천족 입니다.. -판매완료</td>\n",
       "      <td>토끼</td>\n",
       "      <td>2014.11.17.</td>\n",
       "      <td>https://cafe.naver.com/thankmall/ArticleRead.n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9141</th>\n",
       "      <td>털신 정카톤 문의주신분.. 보세요..</td>\n",
       "      <td>토끼</td>\n",
       "      <td>2014.11.12.</td>\n",
       "      <td>https://cafe.naver.com/thankmall/ArticleRead.n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9142</th>\n",
       "      <td>어그실사 올려달라고 댓글주신분... 보세요... -판매완료</td>\n",
       "      <td>토끼</td>\n",
       "      <td>2014.11.12.</td>\n",
       "      <td>https://cafe.naver.com/thankmall/ArticleRead.n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9143</th>\n",
       "      <td>3차물량 &gt;&gt;어그부츠 4000족 입고 되었습니다. -판매완료</td>\n",
       "      <td>토끼</td>\n",
       "      <td>2014.11.10.</td>\n",
       "      <td>https://cafe.naver.com/thankmall/ArticleRead.n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9144</th>\n",
       "      <td>남성 운동화 입고 되었습니다. -판매완료-</td>\n",
       "      <td>토끼</td>\n",
       "      <td>2014.11.10.</td>\n",
       "      <td>https://cafe.naver.com/thankmall/ArticleRead.n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9145</th>\n",
       "      <td>만원빵 행사용으로 매출좋은 복슬복슬 털모카신. -픔절임박</td>\n",
       "      <td>토끼</td>\n",
       "      <td>2014.11.10.</td>\n",
       "      <td>https://cafe.naver.com/thankmall/ArticleRead.n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9146</th>\n",
       "      <td>여성등산화 600족 떙처리합니다. -품절임박</td>\n",
       "      <td>토끼</td>\n",
       "      <td>2014.11.07.</td>\n",
       "      <td>https://cafe.naver.com/thankmall/ArticleRead.n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9147</th>\n",
       "      <td>국산 옥스포드화 400족 처분합니다. -판매완료</td>\n",
       "      <td>토끼</td>\n",
       "      <td>2014.11.07.</td>\n",
       "      <td>https://cafe.naver.com/thankmall/ArticleRead.n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9148</th>\n",
       "      <td>국산 운동화 60족 땡처리요-판매완료</td>\n",
       "      <td>토끼</td>\n",
       "      <td>2014.11.06.</td>\n",
       "      <td>https://cafe.naver.com/thankmall/ArticleRead.n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9149</th>\n",
       "      <td>귀요미 아동 어그 입니다. 기본 스타일로 엄마랑 아가랑 커플 어그로 판매량 좋습니...</td>\n",
       "      <td>토끼</td>\n",
       "      <td>2014.11.06.</td>\n",
       "      <td>https://cafe.naver.com/thankmall/ArticleRead.n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9150</th>\n",
       "      <td>따듯해 크록스 35족 처분합니다. -판매완료</td>\n",
       "      <td>토끼</td>\n",
       "      <td>2014.11.06.</td>\n",
       "      <td>https://cafe.naver.com/thankmall/ArticleRead.n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9151</th>\n",
       "      <td>아동 복실복실 크록스 2000족 땡처리합니다. -판매완료</td>\n",
       "      <td>토끼</td>\n",
       "      <td>2014.11.06.</td>\n",
       "      <td>https://cafe.naver.com/thankmall/ArticleRead.n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9152</th>\n",
       "      <td>패딩부츠. 털부츠 소량 필요하신분... -족당3000원 &lt;판매완료&gt;</td>\n",
       "      <td>토끼</td>\n",
       "      <td>2014.11.06.</td>\n",
       "      <td>https://cafe.naver.com/thankmall/ArticleRead.n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9153</th>\n",
       "      <td>기본 스타일 어그부츠 2차물량 2천족 -2500원 &lt;판매완료&gt;</td>\n",
       "      <td>토끼</td>\n",
       "      <td>2014.11.05.</td>\n",
       "      <td>https://cafe.naver.com/thankmall/ArticleRead.n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9154</th>\n",
       "      <td>국산 운동화 1100족 -완사 진행 &lt;판매완료&gt;</td>\n",
       "      <td>토끼</td>\n",
       "      <td>2014.10.27.</td>\n",
       "      <td>https://cafe.naver.com/thankmall/ArticleRead.n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9155</th>\n",
       "      <td>기본 어그 1500족 땡처리합니다. -판매완료</td>\n",
       "      <td>토끼</td>\n",
       "      <td>2014.10.21.</td>\n",
       "      <td>https://cafe.naver.com/thankmall/ArticleRead.n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9156 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   name         user  \\\n",
       "0                [ 퀄리티 최상급 ] [ 아동복 국산 브랜드 >> 땡처리 합니다 ]          멕가이버   \n",
       "1         [완사입/파샬]퀄리티 좋은 봄 쟈가드 롱 가디건 2컬러 - 200여장 8000원    가비야IPKOREA   \n",
       "2                               [완사입] 언발롱셔츠 - 5장 5000원    가비야IPKOREA   \n",
       "3                  [완사입/파샬] 미시간 쭈리 원피스 2컬러 - 34장 4000원    가비야IPKOREA   \n",
       "4                                   행복한 설명절되세요~~~~~~^^           작은별   \n",
       "5                            쿠첸생산 수출IH다이야몬드철정압력밥솥 10인용            새영   \n",
       "6                                           차렵이불.패드입니다         물고기사랑   \n",
       "7                                      새해 복 많이 받으세요~~~      phss0802   \n",
       "8                                       아동 봄 상하세트 110셋           마마미   \n",
       "9                                        여성 봄니트 대봉 3만원          지구정복   \n",
       "10                                        여성 티셔츠 1000원          지구정복   \n",
       "11                                        망원동~ 옷가게 하실분   gurione6708   \n",
       "12                                4가지싸게처분합니다 먼저가져가심 임자            새영   \n",
       "13                                             아동봄상하세트           마마미   \n",
       "14     쇼핑몰정리 의류재고처리 쇼핑몰폐업 동대문땡처리 땡처리매입 여성의류땡처리 대고의류 ...         더미더미   \n",
       "15                                              몽땅 6만원         물고기사랑   \n",
       "16                       여성 oem 모직 반바지 장당 한가지 장당 1500원           마유리   \n",
       "17                                     핸드메이드 롱코트 난닝구제품        사재기대마왕   \n",
       "18                                                봄 쟈켓       예쁜옷사고시펑   \n",
       "19                                       아동 봄옷 300장 특가           마마미   \n",
       "20                          [완사입] 스트라이프 단가라 10장 -3000원    가비야IPKOREA   \n",
       "21                                           삠뽀요 아동 야상          머스 캣   \n",
       "22                                     선착순 무료 나눔 합니다~!          준배파파   \n",
       "23                                              아동상하세트           마마미   \n",
       "24                             [완사입] 낱장 원피스 10장 -6000원    가비야IPKOREA   \n",
       "25               [완사입/파샬] 여성 반목 베이지 티셔츠 5컬러 -69장 1500원    가비야IPKOREA   \n",
       "26                        [완사입/파샬] 여자친구원피스 - 38장 3500원    가비야IPKOREA   \n",
       "27                                           복 많이 받으세요        빈티지 다온   \n",
       "28                      [완사입/파샬] 언발체크셔츠원피스 - 50장 3500원    가비야IPKOREA   \n",
       "29                                                아동팬티         물고기사랑   \n",
       "...                                                 ...          ...   \n",
       "9126                     여성등산화 450족 잔여수량 땡처리합니다. -판매완료            토끼   \n",
       "9127   브랜드 어그부츠 .... 밑창 확대해서보세요.. 이보다 더 짱짱할수 없는 어그 입...           토끼   \n",
       "9128                   요즘 인기있는 디자인 몇가지 첨부해 봅니다.. -판매완료            토끼   \n",
       "9129                                        어그부츠.-픔절..            토끼   \n",
       "9130   2014년 신상 여성화 땡처리 합니다... 디자인별 수량이 많치 않아요.. 구경먼...           토끼   \n",
       "9131                         어그부츠 1500족 들어왔습니다. -판매완료-            토끼   \n",
       "9132                        아동 패딩. 어그부츠 땡처리합니다. -판매완료-            토끼   \n",
       "9133           국산 사슴어그부츠 >> 동대문 도매가 반가격 땡처리 합니다. -판매완료            토끼   \n",
       "9134                        엄마랑 아가랑 커플 사슴어그 입니다. -판매완료            토끼   \n",
       "9135                              아동부츠 잔여수량 200족 -판매완료            토끼   \n",
       "9136                                      사슴 어그 요-판매완료            토끼   \n",
       "9137   작은싸이즈 부츠 랜덤 3000원 입니다. 최소수량 50족 -수량 조절 가능 <판매...           토끼   \n",
       "9138   아동 부츠 2500족 완사 진행제품입니다. 가격조정해서 파샬구입도 가능합니다. -...           토끼   \n",
       "9139                매년 없어서 못파는 안에 털들은 앵글부츠 입니다. -품절 임박            토끼   \n",
       "9140                       4차물량>>숏 어그부츠 천족 입니다.. -판매완료            토끼   \n",
       "9141                              털신 정카톤 문의주신분.. 보세요..            토끼   \n",
       "9142                  어그실사 올려달라고 댓글주신분... 보세요... -판매완료            토끼   \n",
       "9143                 3차물량 >>어그부츠 4000족 입고 되었습니다. -판매완료            토끼   \n",
       "9144                           남성 운동화 입고 되었습니다. -판매완료-            토끼   \n",
       "9145                   만원빵 행사용으로 매출좋은 복슬복슬 털모카신. -픔절임박            토끼   \n",
       "9146                          여성등산화 600족 떙처리합니다. -품절임박            토끼   \n",
       "9147                        국산 옥스포드화 400족 처분합니다. -판매완료            토끼   \n",
       "9148                              국산 운동화 60족 땡처리요-판매완료            토끼   \n",
       "9149   귀요미 아동 어그 입니다. 기본 스타일로 엄마랑 아가랑 커플 어그로 판매량 좋습니...           토끼   \n",
       "9150                          따듯해 크록스 35족 처분합니다. -판매완료            토끼   \n",
       "9151                   아동 복실복실 크록스 2000족 땡처리합니다. -판매완료            토끼   \n",
       "9152             패딩부츠. 털부츠 소량 필요하신분... -족당3000원 <판매완료>            토끼   \n",
       "9153                기본 스타일 어그부츠 2차물량 2천족 -2500원 <판매완료>            토끼   \n",
       "9154                        국산 운동화 1100족 -완사 진행 <판매완료>            토끼   \n",
       "9155                         기본 어그 1500족 땡처리합니다. -판매완료            토끼   \n",
       "\n",
       "             time                                               link  \n",
       "0           15:41  https://cafe.naver.com/thankmall/ArticleRead.n...  \n",
       "1           14:19  https://cafe.naver.com/thankmall/ArticleRead.n...  \n",
       "2     2019.02.07.  https://cafe.naver.com/thankmall/ArticleRead.n...  \n",
       "3     2019.02.07.  https://cafe.naver.com/thankmall/ArticleRead.n...  \n",
       "4     2019.02.03.  https://cafe.naver.com/thankmall/ArticleRead.n...  \n",
       "5     2019.02.03.  https://cafe.naver.com/thankmall/ArticleRead.n...  \n",
       "6     2019.02.03.  https://cafe.naver.com/thankmall/ArticleRead.n...  \n",
       "7     2019.02.02.  https://cafe.naver.com/thankmall/ArticleRead.n...  \n",
       "8     2019.02.02.  https://cafe.naver.com/thankmall/ArticleRead.n...  \n",
       "9     2019.02.02.  https://cafe.naver.com/thankmall/ArticleRead.n...  \n",
       "10    2019.02.02.  https://cafe.naver.com/thankmall/ArticleRead.n...  \n",
       "11    2019.02.02.  https://cafe.naver.com/thankmall/ArticleRead.n...  \n",
       "12    2019.02.02.  https://cafe.naver.com/thankmall/ArticleRead.n...  \n",
       "13    2019.02.01.  https://cafe.naver.com/thankmall/ArticleRead.n...  \n",
       "14    2019.02.01.  https://cafe.naver.com/thankmall/ArticleRead.n...  \n",
       "15    2019.02.01.  https://cafe.naver.com/thankmall/ArticleRead.n...  \n",
       "16    2019.02.01.  https://cafe.naver.com/thankmall/ArticleRead.n...  \n",
       "17    2019.02.01.  https://cafe.naver.com/thankmall/ArticleRead.n...  \n",
       "18    2019.02.01.  https://cafe.naver.com/thankmall/ArticleRead.n...  \n",
       "19    2019.02.01.  https://cafe.naver.com/thankmall/ArticleRead.n...  \n",
       "20    2019.02.01.  https://cafe.naver.com/thankmall/ArticleRead.n...  \n",
       "21    2019.02.01.  https://cafe.naver.com/thankmall/ArticleRead.n...  \n",
       "22    2019.02.01.  https://cafe.naver.com/thankmall/ArticleRead.n...  \n",
       "23    2019.02.01.  https://cafe.naver.com/thankmall/ArticleRead.n...  \n",
       "24    2019.02.01.  https://cafe.naver.com/thankmall/ArticleRead.n...  \n",
       "25    2019.02.01.  https://cafe.naver.com/thankmall/ArticleRead.n...  \n",
       "26    2019.02.01.  https://cafe.naver.com/thankmall/ArticleRead.n...  \n",
       "27    2019.02.01.  https://cafe.naver.com/thankmall/ArticleRead.n...  \n",
       "28    2019.02.01.  https://cafe.naver.com/thankmall/ArticleRead.n...  \n",
       "29    2019.02.01.  https://cafe.naver.com/thankmall/ArticleRead.n...  \n",
       "...           ...                                                ...  \n",
       "9126  2014.12.09.  https://cafe.naver.com/thankmall/ArticleRead.n...  \n",
       "9127  2014.12.09.  https://cafe.naver.com/thankmall/ArticleRead.n...  \n",
       "9128  2014.12.05.  https://cafe.naver.com/thankmall/ArticleRead.n...  \n",
       "9129  2014.12.02.  https://cafe.naver.com/thankmall/ArticleRead.n...  \n",
       "9130  2014.11.26.  https://cafe.naver.com/thankmall/ArticleRead.n...  \n",
       "9131  2014.11.24.  https://cafe.naver.com/thankmall/ArticleRead.n...  \n",
       "9132  2014.11.19.  https://cafe.naver.com/thankmall/ArticleRead.n...  \n",
       "9133  2014.11.19.  https://cafe.naver.com/thankmall/ArticleRead.n...  \n",
       "9134  2014.11.19.  https://cafe.naver.com/thankmall/ArticleRead.n...  \n",
       "9135  2014.11.19.  https://cafe.naver.com/thankmall/ArticleRead.n...  \n",
       "9136  2014.11.19.  https://cafe.naver.com/thankmall/ArticleRead.n...  \n",
       "9137  2014.11.17.  https://cafe.naver.com/thankmall/ArticleRead.n...  \n",
       "9138  2014.11.17.  https://cafe.naver.com/thankmall/ArticleRead.n...  \n",
       "9139  2014.11.17.  https://cafe.naver.com/thankmall/ArticleRead.n...  \n",
       "9140  2014.11.17.  https://cafe.naver.com/thankmall/ArticleRead.n...  \n",
       "9141  2014.11.12.  https://cafe.naver.com/thankmall/ArticleRead.n...  \n",
       "9142  2014.11.12.  https://cafe.naver.com/thankmall/ArticleRead.n...  \n",
       "9143  2014.11.10.  https://cafe.naver.com/thankmall/ArticleRead.n...  \n",
       "9144  2014.11.10.  https://cafe.naver.com/thankmall/ArticleRead.n...  \n",
       "9145  2014.11.10.  https://cafe.naver.com/thankmall/ArticleRead.n...  \n",
       "9146  2014.11.07.  https://cafe.naver.com/thankmall/ArticleRead.n...  \n",
       "9147  2014.11.07.  https://cafe.naver.com/thankmall/ArticleRead.n...  \n",
       "9148  2014.11.06.  https://cafe.naver.com/thankmall/ArticleRead.n...  \n",
       "9149  2014.11.06.  https://cafe.naver.com/thankmall/ArticleRead.n...  \n",
       "9150  2014.11.06.  https://cafe.naver.com/thankmall/ArticleRead.n...  \n",
       "9151  2014.11.06.  https://cafe.naver.com/thankmall/ArticleRead.n...  \n",
       "9152  2014.11.06.  https://cafe.naver.com/thankmall/ArticleRead.n...  \n",
       "9153  2014.11.05.  https://cafe.naver.com/thankmall/ArticleRead.n...  \n",
       "9154  2014.10.27.  https://cafe.naver.com/thankmall/ArticleRead.n...  \n",
       "9155  2014.10.21.  https://cafe.naver.com/thankmall/ArticleRead.n...  \n",
       "\n",
       "[9156 rows x 4 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_list = post_list.drop_duplicates(subset='name', keep='last')\n",
    "post_list.index = range(len(post_list))\n",
    "\n",
    "post_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_list.to_csv(os.getcwd() + \"/\" + \"cafe_thankmall\" + \".csv\", mode = 'w', header = True, index = None, encoding = 'utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "현민유통김이사             879\n",
       "남양주걸크러쉬             627\n",
       "가비야IPKOREA          445\n",
       "물고기사랑               328\n",
       "최건샵                 289\n",
       "옷파는김사장              281\n",
       "이쁜건다                276\n",
       "작은별                 259\n",
       "마유리                 217\n",
       "향기로운만남              190\n",
       "썬스페이스               157\n",
       "행복이1                147\n",
       "쇼미더머니               134\n",
       "이싸                  128\n",
       "범진통상                120\n",
       "선장                  112\n",
       "알제이샵                 96\n",
       "더미더미                 94\n",
       "토끼                   93\n",
       "대박포촤                 91\n",
       "소량대량                 79\n",
       "소다아동복                77\n",
       "울루맘                  76\n",
       "잡화상                  75\n",
       "비엠의류                 74\n",
       "리더스코리아               70\n",
       "이벤트                  68\n",
       "뿌요뿌요                 65\n",
       "도도맘                  61\n",
       "린꽃                   61\n",
       "                   ... \n",
       "무지개창고                 1\n",
       "수산 is1877 kapsan      1\n",
       "진진진진                  1\n",
       "yruiyqq               1\n",
       "렝가                    1\n",
       "쏘롱이                   1\n",
       "왕눈이삼촌                 1\n",
       "대박장터                  1\n",
       "스토리제이                 1\n",
       "굳센넘                   1\n",
       "잇스 ITS                1\n",
       "멋진나                   1\n",
       "아이소율                  1\n",
       "스타일조아                 1\n",
       "hongannghia           1\n",
       "임진섭                   1\n",
       "ㅇ일체유심조ㅇ               1\n",
       "쥬시007                 1\n",
       "luv6253               1\n",
       "수현맘은서                 1\n",
       "제이라벨                  1\n",
       "봉봉주세                  1\n",
       "시완이아빠                 1\n",
       "청주화물                  1\n",
       "리라윤                   1\n",
       "파란악마                  1\n",
       "김셀프                   1\n",
       "툴맨2                   1\n",
       "더질러                   1\n",
       "DS유1통                 1\n",
       "Name: user, Length: 611, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_list['user'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_list['user'].value_counts().to_csv(os.getcwd() + \"/\" + \"cafe_thankmall_userlist\" + \".csv\", mode = 'w', header = True, encoding = 'utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 땡몰 여성, 남성 의류 덤핑 크롤러"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "delay = 3\n",
    "base_url = 'https://cafe.naver.com/thankmall'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser = Chrome()\n",
    "browser.maximize_window()\n",
    "time.sleep(2)\n",
    "browser.get(base_url)\n",
    "browser.implicitly_wait(delay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "body = browser.find_element_by_tag_name('body')\n",
    "num_page_down = 2\n",
    "while num_page_down:\n",
    "    body.send_keys(Keys.PAGE_DOWN)\n",
    "    time.sleep(1)\n",
    "    num_page_down -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#제어 환경에 보여야 함\n",
    "browser.find_elements_by_xpath('//*[@id = \"group95\"]/li[1]/a')[0].click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dumping_data = pd.DataFrame({'post_title':[],\n",
    "                           'owner':[],\n",
    "                           'date':[],\n",
    "                           'url':[]})\n",
    "#ifrme to html 코드 굉장히 중요함\n",
    "browser.switch_to_frame(browser.find_element_by_name('cafe_main'))\n",
    "for i in range(1,3):\n",
    "    a=i\n",
    "    for j in range(1,12):#그래야 1~11까지의 범위가 됨\n",
    "        try:\n",
    "            if a==1:\n",
    "                body = browser.find_element_by_tag_name('body')\n",
    "                num_page_down = 1\n",
    "                while num_page_down:\n",
    "                    body.send_keys(Keys.PAGE_DOWN)\n",
    "                    time.sleep(1)\n",
    "                    num_page_down -= 1\n",
    "                browser.find_elements_by_xpath('//*[@class = \"prev-next\"]/a['+ str(j) +']')[0].click()\n",
    "\n",
    "                    \n",
    "                html0 = browser.page_source    \n",
    "                html= BeautifulSoup(html0,'html.parser')\n",
    "                post0 = html.find_all('div',{'class':'article-board m-tcol-c'})[1]\n",
    "                post1 = post0.find('tbody')\n",
    "                \n",
    "                post_title0 = post1.find_all('a',{'class':'article'})\n",
    "                post_owner0 = post1.find_all('td',{'class':'p-nick'})\n",
    "                post_date0 = post1.find_all('td',{'class':'td_date'})\n",
    "                \n",
    "                insert_data = pd.DataFrame({'post_title':[],\n",
    "                                           'owner':[],\n",
    "                                           'date':[],\n",
    "                                           'url':[]})\n",
    "                for post in range(len(post_title0)):\n",
    "                    post_title = \"\".join(post_title0[post].text.split())\n",
    "                    post_url = 'http://cafe.naver.com'+ post_title0[post]['href']\n",
    "                    post_owner = post_owner0[post].find('a').text\n",
    "                    post_date = post_date0[post].text\n",
    "                    \n",
    "                    insert_data2 =  pd.DataFrame({'post_title':[post_title],\n",
    "                                           'owner':[post_owner],\n",
    "                                           'date':[post_date],\n",
    "                                           'url':[post_url]})\n",
    "                    insert_data = insert_data.append(insert_data2)\n",
    "                    \n",
    "                dumping_data = dumping_data.append(insert_data)\n",
    "                \n",
    "            else:\n",
    "                if j == 1:\n",
    "                    pass\n",
    "                else:\n",
    "                    body = browser.find_element_by_tag_name('body')\n",
    "                    num_page_down = 1\n",
    "                    while num_page_down:\n",
    "                        body.send_keys(Keys.PAGE_DOWN)\n",
    "                        time.sleep(1)\n",
    "                        num_page_down -= 1\n",
    "                    browser.find_elements_by_xpath('//*[@class = \"prev-next\"]/a['+ str(j+1) +']')[0].click()\n",
    "\n",
    "                \n",
    "                html0 = browser.page_source    \n",
    "                html= BeautifulSoup(html0,'html.parser')\n",
    "                post0 = html.find_all('div',{'class':'article-board m-tcol-c'})[1]\n",
    "                post1 = post0.find('tbody')\n",
    "                \n",
    "                post_title0 = post1.find_all('a',{'class':'article'})\n",
    "                post_owner0 = post1.find_all('td',{'class':'p-nick'})\n",
    "                post_date0 = post1.find_all('td',{'class':'td_date'})\n",
    "                \n",
    "                insert_data = pd.DataFrame({'post_title':[],\n",
    "                                           'owner':[],\n",
    "                                           'date':[],\n",
    "                                           'url':[]})\n",
    "                for post in range(len(post_title0)):\n",
    "                    post_title = \"\".join(post_title0[post].text.split())\n",
    "                    post_url = 'http://cafe.naver.com'+ post_title0[post]['href']\n",
    "                    post_owner = post_owner0[post].find('a').text\n",
    "                    post_date = post_date0[post].text\n",
    "                    \n",
    "                    insert_data2 =  pd.DataFrame({'post_title':[post_title],\n",
    "                                           'owner':[post_owner],\n",
    "                                           'date':[post_date],\n",
    "                                           'url':[post_url]})\n",
    "                    insert_data = insert_data.append(insert_data2)\n",
    "                    \n",
    "                dumping_data = dumping_data.append(insert_data)\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dumping_data.index = range(len(dumping_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 긁는 도중 삭제한 게시글이 있어서 다시 진행해야ㅑ함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dumping_data2 = dumping_data.iloc[-7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 본문 긁어오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url2  = dumping_data['url'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser = Chrome()\n",
    "browser.maximize_window()\n",
    "time.sleep(2)\n",
    "browser.get(base_url2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_main_data = pd.DataFrame({'post_title':[],\n",
    "                           'owner':[],\n",
    "                           'date':[],\n",
    "                           'url':[],\n",
    "                           'main_text':[]})\n",
    "for i in range(0,101):\n",
    "    try:\n",
    "        base_url2 = dumping_data['url'].iloc[i]\n",
    "        browser.get(base_url2)\n",
    "        browser.implicitly_wait(delay)\n",
    "        #새창을 켜게 된다면 로그인을 새로해야 하는데 네이버 측에서 자동 제어 로그인을 막아놨기 때문에\n",
    "        #먼저 로그인을 한 후 진행해야 함\n",
    "\n",
    "        post_title = dumping_data['post_title'].iloc[i]\n",
    "        owner = dumping_data['owner'].iloc[i]\n",
    "        date = dumping_data['date'].iloc[i]\n",
    "\n",
    "        browser.switch_to_frame(browser.find_element_by_name('cafe_main'))\n",
    "        html_all0 = browser.page_source\n",
    "        html_all = BeautifulSoup(html_all0,'html.parser')\n",
    "\n",
    "        post_text = str(html_all.find('div',{'class':'tbody m-tcol-c'}).get_text())\n",
    "        post_text2 = re.sub('\\xa0',' ',post_text)\n",
    "\n",
    "        if 'img' in str(html_all.find('div',{'class':'tbody m-tcol-c'})):\n",
    "            post_img = html_all.find('div',{'class':'tbody m-tcol-c'}).find_all('img')\n",
    "            #src를 어떻게 코드상에 최적화 시킬지\n",
    "            for i in range(len(post_img)):\n",
    "                img_0 = post_img[i]['src']\n",
    "                img_source = '<img src = '+ '\"'+img_0+ '\"'+' >\\n'\n",
    "                post_text3 = post_text2 + img_source\n",
    "            main_text = post_text3\n",
    "        else:\n",
    "            main_text = post_text2\n",
    "\n",
    "\n",
    "        url = base_url2\n",
    "\n",
    "        insert_data = pd.DataFrame({'post_title':[post_title],\n",
    "                               'owner':[owner],\n",
    "                               'date':[date],\n",
    "                               'url':[url],\n",
    "                               'main_text':[main_text]})\n",
    "        post_main_data = post_main_data.append(insert_data)\n",
    "    except:\n",
    "        pass\n",
    "post_main_data.index = range(len(post_main_data))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_title</th>\n",
       "      <th>owner</th>\n",
       "      <th>date</th>\n",
       "      <th>url</th>\n",
       "      <th>main_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019년홈쇼핑대박상품여성의류최저가공급</td>\n",
       "      <td>행복이보인다</td>\n",
       "      <td>15:43</td>\n",
       "      <td>http://cafe.naver.com/ArticleRead.nhn?clubid=2...</td>\n",
       "      <td>\\n \\n&lt;img src = \"https://cafeptthumb-phinf.pst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>비비드,웜,네온컬러셔츠2000원</td>\n",
       "      <td>덤핑구</td>\n",
       "      <td>15:08</td>\n",
       "      <td>http://cafe.naver.com/ArticleRead.nhn?clubid=2...</td>\n",
       "      <td>\\n#의류 #덤핑 #국내생산 #동대문국내생산 동대문 셔츠 판매합니다.컬러는 비비드,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>남성피그먼트워싱밴딩팬츠정리합니다.</td>\n",
       "      <td>스타일조아</td>\n",
       "      <td>2019.04.11.</td>\n",
       "      <td>http://cafe.naver.com/ArticleRead.nhn?clubid=2...</td>\n",
       "      <td>\\n피그먼트 워싱 돌린 밴딩 팬츠입니다.프리사이즈로 남성 허리 34까지는 무난하게 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>홈쇼핑요가복5종1000원에100셋트씩판매합니다.</td>\n",
       "      <td>썬스페이스</td>\n",
       "      <td>2019.04.11.</td>\n",
       "      <td>http://cafe.naver.com/ArticleRead.nhn?clubid=2...</td>\n",
       "      <td>\\n안녕하세요?일산창고 \"땡스토리 \"입니다.홈쇼핑 요가복5종1000원에100셋트씩판...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>니트롱가디건입니다</td>\n",
       "      <td>하스모나</td>\n",
       "      <td>2019.04.11.</td>\n",
       "      <td>http://cafe.naver.com/ArticleRead.nhn?clubid=2...</td>\n",
       "      <td>\\n니트 롱 가디건 입니다국산 제품입니다수량이 많이 없습니다장당 5,000원010 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>봄.여름원피스.블라우스특가(초이스가능)</td>\n",
       "      <td>하스모나</td>\n",
       "      <td>2019.04.11.</td>\n",
       "      <td>http://cafe.naver.com/ArticleRead.nhn?clubid=2...</td>\n",
       "      <td>\\n원피스.블라우스 동대문 밤시장 제품입니다.여러가지 스타일로 만여장 입니다더 많은...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>여성브랜드팬티..600원</td>\n",
       "      <td>물고기사랑</td>\n",
       "      <td>2019.04.10.</td>\n",
       "      <td>http://cafe.naver.com/ArticleRead.nhn?clubid=2...</td>\n",
       "      <td>\\n코튼클럽.BYC 제품입니다 사이즈90호만...인견.순먼.라이크라 ...010.9...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   post_title   owner         date  \\\n",
       "0       2019년홈쇼핑대박상품여성의류최저가공급  행복이보인다        15:43   \n",
       "1           비비드,웜,네온컬러셔츠2000원     덤핑구        15:08   \n",
       "2          남성피그먼트워싱밴딩팬츠정리합니다.   스타일조아  2019.04.11.   \n",
       "3  홈쇼핑요가복5종1000원에100셋트씩판매합니다.   썬스페이스  2019.04.11.   \n",
       "4                   니트롱가디건입니다    하스모나  2019.04.11.   \n",
       "5       봄.여름원피스.블라우스특가(초이스가능)    하스모나  2019.04.11.   \n",
       "6               여성브랜드팬티..600원   물고기사랑  2019.04.10.   \n",
       "\n",
       "                                                 url  \\\n",
       "0  http://cafe.naver.com/ArticleRead.nhn?clubid=2...   \n",
       "1  http://cafe.naver.com/ArticleRead.nhn?clubid=2...   \n",
       "2  http://cafe.naver.com/ArticleRead.nhn?clubid=2...   \n",
       "3  http://cafe.naver.com/ArticleRead.nhn?clubid=2...   \n",
       "4  http://cafe.naver.com/ArticleRead.nhn?clubid=2...   \n",
       "5  http://cafe.naver.com/ArticleRead.nhn?clubid=2...   \n",
       "6  http://cafe.naver.com/ArticleRead.nhn?clubid=2...   \n",
       "\n",
       "                                           main_text  \n",
       "0  \\n \\n<img src = \"https://cafeptthumb-phinf.pst...  \n",
       "1  \\n#의류 #덤핑 #국내생산 #동대문국내생산 동대문 셔츠 판매합니다.컬러는 비비드,...  \n",
       "2  \\n피그먼트 워싱 돌린 밴딩 팬츠입니다.프리사이즈로 남성 허리 34까지는 무난하게 ...  \n",
       "3  \\n안녕하세요?일산창고 \"땡스토리 \"입니다.홈쇼핑 요가복5종1000원에100셋트씩판...  \n",
       "4  \\n니트 롱 가디건 입니다국산 제품입니다수량이 많이 없습니다장당 5,000원010 ...  \n",
       "5  \\n원피스.블라우스 동대문 밤시장 제품입니다.여러가지 스타일로 만여장 입니다더 많은...  \n",
       "6  \\n코튼클럽.BYC 제품입니다 사이즈90호만...인견.순먼.라이크라 ...010.9...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_main_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
